{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPlq2fbwC8AupVTdoxflmAh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## **Summary of Kautz's Taxonomy of Neuro-symbolic Architectures:**\n","\n","1. Neural Network-Only Systems\n","2. Symbolic-Only Systems\n","3. End-to-End Neural Networks with Structured Output\n","4. Neuro-Symbolic Hybrid Architectures\n","5. Deep Neuro-Symbolic Systems\n","\n","Kautz's taxonomy provides a useful framework to understand the different ways that neural and symbolic systems can be integrated to achieve more flexible, general AI. These approaches range from simpler forms of combination, like neural networks augmented by symbolic constraints, to more sophisticated forms, like meta-level integration where the system reflects on and improves its own reasoning and learning processes. As neuro-symbolic AI continues to evolve, these categories will likely become more refined, and new approaches may emerge, bridging the gap toward ***Artificial General Intelligence (AGI).***\n","\n","\n","\n","\n","\n"],"metadata":{"id":"TowtxFf-PjZT"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbQYCpuROhxU","executionInfo":{"status":"ok","timestamp":1731849411120,"user_tz":-330,"elapsed":128548,"user":{"displayName":"Vijayananda Mohire","userId":"16579720561741340503"}},"outputId":"adcbd333-73a1-43eb-df73-30ea49d24f00"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 56.5MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28.9k/28.9k [00:00<00:00, 1.87MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1.65M/1.65M [00:00<00:00, 13.9MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4.54k/4.54k [00:00<00:00, 9.33MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.17623372375965118\n","Epoch 2, Loss: 0.07837896049022675\n","Epoch 3, Loss: 0.04556576535105705\n","Epoch 4, Loss: 0.08952396363019943\n","Epoch 5, Loss: 0.04567892104387283\n"]}],"source":["# 1.\tNeural Network-Only\n","# In this example, we'll create a simple neural network for classification using PyTorch. It will learn from a dataset (e.g., MNIST) and classify digits.\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","\n","# Define a simple feedforward neural network\n","class SimpleNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleNN, self).__init__()\n","        self.fc1 = nn.Linear(28 * 28, 128)  # 28x28 image flattened to 1D vector of length 784\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 10)  # 10 classes for MNIST digits\n","\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","# Load MNIST dataset\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n","\n","# Initialize network and optimizer\n","model = SimpleNN()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Training loop\n","for epoch in range(5):  # 5 epochs for demonstration\n","    for data, target in trainloader:\n","        data = data.view(-1, 28 * 28)  # Flatten image to 1D vector\n","        optimizer.zero_grad()\n","        output = model(data)  # Forward pass\n","        loss = criterion(output, target)  # Calculate loss\n","        loss.backward()  # Backpropagation\n","        optimizer.step()  # Update weights\n","    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n","\n","# Example testing code (optional)\n","# You would test the network on a validation/test set here.\n"]},{"cell_type":"markdown","source":["**Code sample generated by ChatGPT, executed by Bhadale IT**"],"metadata":{"id":"yTOFUdxqcS4z"}}]}